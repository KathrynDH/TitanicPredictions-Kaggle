# Titanic-Kaggle

This is my notebook for Kaggle's competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/overview).

I created [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and used [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to determine the best hyperparameters for three different classifiers: [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), and [XGBClassifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html).  
The goal of this competition is to predict which passengers on the Titanic survived.

Data for this project can be viewed here: [Kaggle.com - Titanic: Machine Learning from Disaster - Data](https://www.kaggle.com/c/titanic/data)

View the notebook using Jupyter nbviewer: [https://nbviewer.jupyter.org/github/KathrynDH/TitanicPredictions-Kaggle/blob/main/pipelinesgridsearch-titanic-disaster.ipynb](https://nbviewer.jupyter.org/github/KathrynDH/TitanicPredictions-Kaggle/blob/main/pipelinesgridsearch-titanic-disaster.ipynb)
